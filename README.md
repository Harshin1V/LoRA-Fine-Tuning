
# LoRA Fine Tuning

This repository demonstrates fine-tuning [TinyLlama](https://huggingface.co/cognitionai/TinyLlama-1.1B-Chat-v1.0) models using Low-Rank Adaptation (LoRA), a parameter-efficient technique for adapting pre-trained language models to downstream tasks with reduced computational cost.

---

## ğŸ§  What is LoRA?

LoRA (Low-Rank Adaptation) is a training technique that allows you to insert trainable low-rank matrices into the attention layers of a Transformer model while keeping the original pre-trained weights frozen. This significantly reduces the number of trainable parameters and allows efficient fine-tuning even on low-resource hardware.

---

## ğŸ—‚ï¸ Repository Structure

```bash
â”œâ”€â”€ Fine-Tuning_TinyLlama_Frobinate.ipynb      # Fine-tuning on the "Frobinate" dataset
â”œâ”€â”€ Fine-Tuning_TinyLlama_Math.ipynb           # Fine-tuning on the "Math" dataset
â”œâ”€â”€ Evaluation_TinyLlama_Frobinate.ipynb       # Evaluation for "Frobinate" fine-tuned model
â”œâ”€â”€ Evaluation_TinyLlama_Math.ipynb            # Evaluation for "Math" fine-tuned model
â”œâ”€â”€ frobinate.jsonl                            # Training data for "Frobinate"
â”œâ”€â”€ frobinate_test.jsonl                       # Test data for "Frobinate"
â””â”€â”€ README.md
```
